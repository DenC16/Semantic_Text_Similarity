{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Ui9higSHjx"
      },
      "source": [
        "Count Vectorizer method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qSyY5uGSRdC"
      },
      "source": [
        "# PROBLEM STATEMENT\n",
        "\n",
        "Semantic Textual Similarity (STS) assesses the degree to which two sentences are semantically equivalent to each other. Given two paragraphs, quantify the degree of similarity between the two text-based on Semantic similarity. The task is to predict a value between 0-1 indicating the similarity between the pair of text paras.\n",
        "\n",
        "# Data :\n",
        "\n",
        "The data contains a pair of paragraphs. These text paragraphs are randomly sampled from a raw\n",
        "dataset. Each pair of the sentence may or may not be semantically similar. The candidate is to\n",
        "predict a value between 0-1 indicating a degree of similarity between the pair of text paras.\n",
        "\n",
        "0 means highly similar\n",
        "\n",
        "1 means highly dissimilar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZFjEukZsUAfk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\dhyan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Importing packages \n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Importing packages for pre-processing texts\n",
        "import re                                                                        # for regular expressions\n",
        "import nltk                                                                      # for text manipulation\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2ggkJ2Y9UF4M"
      },
      "outputs": [],
      "source": [
        "# loading the dataset\n",
        "df = pd.read_csv('Precily_Text_Similarity.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>broadband challenges tv viewing the number of ...</td>\n",
              "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
              "      <td>amnesty chief laments war failure the lack of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>player burn-out worries robinson england coach...</td>\n",
              "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
              "      <td>redford s vision of sundance despite sporting ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
              "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>2995</td>\n",
              "      <td>uk directors guild nominees named martin scors...</td>\n",
              "      <td>steel firm  to cut  45 000 jobs mittal steel  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>2996</td>\n",
              "      <td>u2 to play at grammy awards show irish rock ba...</td>\n",
              "      <td>israel looks to us for bank chief israel has a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>2997</td>\n",
              "      <td>pountney handed ban and fine northampton coach...</td>\n",
              "      <td>india and iran in gas export deal india has si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>2998</td>\n",
              "      <td>belle named  best scottish band  belle &amp; sebas...</td>\n",
              "      <td>mido makes third apology ahmed  mido  hossam h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>2999</td>\n",
              "      <td>criminal probe on citigroup deals traders at u...</td>\n",
              "      <td>former ni minister scott dies former northern ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID                                              text1  \\\n",
              "0        0  broadband challenges tv viewing the number of ...   \n",
              "1        1  rap boss arrested over drug find rap mogul mar...   \n",
              "2        2  player burn-out worries robinson england coach...   \n",
              "3        3  hearts of oak 3-2 cotonsport hearts of oak set...   \n",
              "4        4  sir paul rocks super bowl crowds sir paul mcca...   \n",
              "...    ...                                                ...   \n",
              "2995  2995  uk directors guild nominees named martin scors...   \n",
              "2996  2996  u2 to play at grammy awards show irish rock ba...   \n",
              "2997  2997  pountney handed ban and fine northampton coach...   \n",
              "2998  2998  belle named  best scottish band  belle & sebas...   \n",
              "2999  2999  criminal probe on citigroup deals traders at u...   \n",
              "\n",
              "                                                  text2  \n",
              "0     gardener wins double in glasgow britain s jaso...  \n",
              "1     amnesty chief laments war failure the lack of ...  \n",
              "2     hanks greeted at wintry premiere hollywood sta...  \n",
              "3     redford s vision of sundance despite sporting ...  \n",
              "4     mauresmo opens with victory in la amelie maure...  \n",
              "...                                                 ...  \n",
              "2995  steel firm  to cut  45 000 jobs mittal steel  ...  \n",
              "2996  israel looks to us for bank chief israel has a...  \n",
              "2997  india and iran in gas export deal india has si...  \n",
              "2998  mido makes third apology ahmed  mido  hossam h...  \n",
              "2999  former ni minister scott dies former northern ...  \n",
              "\n",
              "[3000 rows x 3 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.insert(0, 'ID', range(0, len(df)))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'broadband challenges tv viewing the number of europeans with broadband has exploded over the past 12 months  with the web eating into tv viewing habits  research suggests.  just over 54 million people are hooked up to the net via broadband  up from 34 million a year ago  according to market analysts nielsen/netratings. the total number of people online in europe has broken the 100 million mark. the popularity of the net has meant that many are turning away from tv  say analysts jupiter research. it found that a quarter of web users said they spent less time watching tv in favour of the net  the report by nielsen/netratings found that the number of people with fast internet access had risen by 60% over the past year.  the biggest jump was in italy  where it rose by 120%. britain was close behind  with broadband users almost doubling in a year. the growth has been fuelled by lower prices and a wider choice of always-on  fast-net subscription plans.  twelve months ago high speed internet users made up just over one third of the audience in europe; now they are more than 50% and we expect this number to keep growing   said gabrielle prior  nielsen/netratings analyst.  as the number of high-speed surfers grows  websites will need to adapt  update and enhance their content to retain their visitors and encourage new ones.  the total number of europeans online rose by 12% to 100 million over the past year  the report showed  with the biggest rise in france  italy  britain and germany.  the ability to browse web pages at high speed  download files such as music or films and play online games is changing what people do in their spare time.  a study by analysts jupiter research suggested that broadband was challenging television viewing habits. in homes with broadband  40% said they were spending less time watching tv. the threat to tv was greatest in countries where broadband was on the up  in particular the uk  france and spain  said the report. it said tv companies faced a major long-term threat over the next five years  with broadband predicted to grow from 19% to 37% of households by 2009.  year-on-year we are continuing to see a seismic shift in where  when and how europe s population consume media for information and entertainment and this has big implications for tv  newspaper and radio   said jupiter research analyst olivier beauvillian.'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"text1\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'gardener wins double in glasgow britain s jason gardener enjoyed a double 60m success in glasgow in his first competitive outing since he won 100m relay gold at the athens olympics.  gardener cruised home ahead of scot nick smith to win the invitational race at the norwich union international. he then recovered from a poor start in the second race to beat swede daniel persson and italy s luca verdecchia. his times of 6.61 and 6.62 seconds were well short of american maurice greene s 60m world record of 6.39secs from 1998.  it s a very hard record to break  but i believe i ve trained very well   said the world indoor champion  who hopes to get closer to the mark this season.  it was important to come out and make sure i got maximum points. my last race was the olympic final and there was a lot of expectation.  this was just what i needed to sharpen up and get some race fitness. i m very excited about the next couple of months.   double olympic champion  marked her first appearance on home soil since winning 1500m and 800m gold in athens with a victory. there was a third success for britain when  edged out russia s olga fedorova and sweden s jenny kallur to win the women s 60m race in 7.23secs. maduaka was unable to repeat the feat in the 200m  finishing down in fourth as  took the win for russia. and the 31-year-old also missed out on a podium place in the 4x200m relay as the british quartet came in fourth  with russia setting a new world indoor record. there was a setback for jade johnson as she suffered a recurrence of her back injury in the long jump. russia won the meeting with a final total of 63 points  with britain second on 48 and france one point behind in third.  led the way for russia by producing a major shock in the high jump as he beat olympic champion stefan holm into second place to end the swede s 22-event unbeaten record.  won the triple jump with a leap of 16.87m  with britain s tosin oke fourth in 15.80m.  won the men s pole vault competition with a clearance of 5.65m  with britain s nick buckfield 51cm adrift of his personal best in third. and  won the women s 800m  with britain s jenny meadows third. there was yet another russian victory in the women s 400m as  finished well clear of britain s catherine murphy. chris lambert had to settle for fourth after fading in the closing stages of the men s 200m race as sweden s  held off leslie djhone of france. france s  won the men s 400m  with brett rund fourth for britain.  took victory for sweden in the women s 60m hurdles ahead of russia s irina shevchenko and britain s sarah claxton  who set a new personal best. italy grabbed their first victory in the men s 1500m as  kicked over the last 200 metres to hold off britain s james thie and france s alexis abraham. a botched changeover in the 4x200m relay cost britain s men the chance to add further points as france claimed victory.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.text2[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vfd_8mT-UT8M"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')\n",
        "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RyUePDlfUdME"
      },
      "outputs": [],
      "source": [
        "# function to preprocess texts\n",
        "def preprocess(text, stem=True):\n",
        "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
        "  tokens = []\n",
        "  for token in text.split():\n",
        "    if token not in stop_words:\n",
        "      if stem:\n",
        "        tokens.append(stemmer.stem(token))\n",
        "      else:\n",
        "        tokens.append(token)\n",
        "  return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lQRfpdvlUhK8"
      },
      "outputs": [],
      "source": [
        "df.text1 = df.text1.apply(lambda x: preprocess(x))\n",
        "df.text2 = df.text2.apply(lambda x: preprocess(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "deFMTENkXo_U"
      },
      "outputs": [],
      "source": [
        "text1 = df.text1.tolist()\n",
        "text2 = df.text2.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "wNGvtbzTU8os",
        "outputId": "1cecaf84-c891-48ed-95d2-8cf64b8ffff4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>broadband challeng tv view number european bro...</td>\n",
              "      <td>garden win doubl glasgow britain jason garden ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rap boss arrest drug find rap mogul marion sug...</td>\n",
              "      <td>amnesti chief lament war failur lack public ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>player burn worri robinson england coach andi ...</td>\n",
              "      <td>hank greet wintri premier hollywood star tom h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>heart oak 3 2 cotonsport heart oak set ghanaia...</td>\n",
              "      <td>redford vision sundanc despit sport corduroy c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>sir paul rock super bowl crowd sir paul mccart...</td>\n",
              "      <td>mauresmo open victori la ameli mauresmo maria ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                              text1  \\\n",
              "0   0  broadband challeng tv view number european bro...   \n",
              "1   1  rap boss arrest drug find rap mogul marion sug...   \n",
              "2   2  player burn worri robinson england coach andi ...   \n",
              "3   3  heart oak 3 2 cotonsport heart oak set ghanaia...   \n",
              "4   4  sir paul rock super bowl crowd sir paul mccart...   \n",
              "\n",
              "                                               text2  \n",
              "0  garden win doubl glasgow britain jason garden ...  \n",
              "1  amnesti chief lament war failur lack public ou...  \n",
              "2  hank greet wintri premier hollywood star tom h...  \n",
              "3  redford vision sundanc despit sport corduroy c...  \n",
              "4  mauresmo open victori la ameli mauresmo maria ...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preprocessed dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qdJQtLNcSEFL"
      },
      "outputs": [],
      "source": [
        "# Creating a function to find the cosine similarity between a pair of texts\n",
        "def countvectorizer_cosine_distance_method(s1, s2):\n",
        "    \n",
        "    # sentences to list\n",
        "    allsentences = [s1 , s2]\n",
        "     \n",
        "    # text to vector\n",
        "    vectorizer = CountVectorizer()\n",
        "    all_sentences_to_vector = vectorizer.fit_transform(allsentences)            # Vectorization through Bag of Words method\n",
        "    text_to_vector_v1 = all_sentences_to_vector.toarray()[0].tolist()\n",
        "    text_to_vector_v2 = all_sentences_to_vector.toarray()[1].tolist()\n",
        "    \n",
        "    # distance of similarity\n",
        "    cos_dist = cosine(text_to_vector_v1, text_to_vector_v2)\n",
        "    return (1-cos_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RboMMhB4Wg6M"
      },
      "outputs": [],
      "source": [
        "similarity_score=[]\n",
        "for index, row in df.iterrows():\n",
        "  cosine_similarity = countvectorizer_cosine_distance_method(text1[index], text2[index])\n",
        "  similarity_score.append(cosine_similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we get the value ranging from -1 to 1. But, we need values ranging from 0 to 1 hence we will add 1 to the cosine similarity value and then normalize it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oQIzJQg7X3XG"
      },
      "outputs": [],
      "source": [
        "Similarity_Score = [((x+1)/2) for x in similarity_score]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    3000.000000\n",
              "mean        0.543828\n",
              "std         0.029502\n",
              "min         0.500000\n",
              "25%         0.524828\n",
              "50%         0.537786\n",
              "75%         0.555115\n",
              "max         1.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series(Similarity_Score).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Q3_bBY7TX9Qt"
      },
      "outputs": [],
      "source": [
        "df = df.assign(Similarity_Score = Similarity_Score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[[\"ID\",\"Similarity_Score\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "9A_bpVtzYDt8",
        "outputId": "d7d163e2-3aa8-4dfb-9017-ce5f090aa828"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Similarity_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.558715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.519592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.536538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.520178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.554313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  Similarity_Score\n",
              "0   0          0.558715\n",
              "1   1          0.519592\n",
              "2   2          0.536538\n",
              "3   3          0.520178\n",
              "4   4          0.554313"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"STS_score.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BE-FwJ1GRVFV"
      },
      "outputs": [],
      "source": [
        "#two example texts\n",
        "sent1 = 'The prime minister modi greets the press in Chennai'\n",
        "sent2 = 'Modi speaks to the media in Chennai'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DJoGpRHSTjs",
        "outputId": "1bc36741-6755-4b98-97c5-1ecdafccba83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5698028822981898"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "countvectorizer_cosine_distance_method(sent1, sent2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPCGNtNnAF0dxfQEpMDjWB/",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "1iJC-x_iHwudzlt6mVlZhabV-7JfkVKZ3",
      "name": "count_vectorizer_sts.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "9f5475ab6801b18d62dd78561df7cad099807d3c18f11eefa2edcbf56bb9e19a"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
